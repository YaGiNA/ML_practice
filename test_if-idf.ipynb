{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = os.path.abspath('./liar_dataset/train.tsv')\n",
    "test_file = os.path.abspath('./liar_dataset/test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_title(train_file):\n",
    "    tfs, titles = [], []\n",
    "    with open(train_file, \"r\") as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            cols = line.split(\"\\t\")\n",
    "            raw_tf = cols[1]\n",
    "            if raw_tf in {\"false\", \"pants-fire\"}:\n",
    "                tf = False\n",
    "            else:\n",
    "                tf = True\n",
    "            title = cols[2]\n",
    "            tfs.append(tf)\n",
    "            titles.append(title)\n",
    "            line = f.readline()\n",
    "    infos = [tfs, titles]     \n",
    "    return infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_infos, test_infos = get_tf_title(train_file), get_tf_title(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://moritamori.hatenablog.com/entry/tfidf_vectorizer\n",
    "def make_tfidf_vec(infos):\n",
    "    vec = TfidfVectorizer(max_df=10, ngram_range=(1, 1), sublinear_tf=True, norm='l2', stop_words='english')\n",
    "    docs = train_infos[1]\n",
    "    term_doc = vec.fit_transform(docs)\n",
    "    info_x = term_doc.toarray()\n",
    "    info_y = infos[0]\n",
    "    return info_x, info_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = make_tfidf_vec(train_infos)\n",
    "test_x, test_y = make_tfidf_vec(test_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10269, 10197)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#https://qiita.com/kazuki_hayakawa/items/18b7017da9a6f73eba77\n",
    "# 線形SVMのインスタンスを生成\n",
    "model = SVC(kernel='linear', random_state=None)\n",
    "\n",
    "# モデルの学習。fit関数で行う。\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
