{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_ifidf import get_tf_title\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from gensim.models import word2vec\n",
    "import pickle\n",
    "import logging\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = os.path.abspath('./liar_dataset/train.tsv')\n",
    "test_file = os.path.abspath('./liar_dataset/test.tsv')\n",
    "train_infos, test_infos = get_tf_title(train_file), get_tf_title(test_file)\n",
    "infos = [train_infos[0] + test_infos[0], train_infos[1] + test_infos[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('quotes.txt', 'w') as f:\n",
    "    quotes = infos[1]\n",
    "    for quote in quotes:\n",
    "        f.write(quote + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-18 15:43:53,664 : INFO : collecting all words and their counts\n",
      "2018-07-18 15:43:53,666 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-07-18 15:43:53,724 : INFO : collected 23409 word types from a corpus of 206936 raw words and 21 sentences\n",
      "2018-07-18 15:43:53,726 : INFO : Loading a fresh vocabulary\n",
      "2018-07-18 15:43:53,815 : INFO : min_count=1 retains 23409 unique words (100% of original 23409, drops 0)\n",
      "2018-07-18 15:43:53,816 : INFO : min_count=1 leaves 206936 word corpus (100% of original 206936, drops 0)\n",
      "2018-07-18 15:43:53,886 : INFO : deleting the raw counts dictionary of 23409 items\n",
      "2018-07-18 15:43:53,887 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2018-07-18 15:43:53,887 : INFO : downsampling leaves estimated 170977 word corpus (82.6% of prior 206936)\n",
      "2018-07-18 15:43:53,936 : INFO : estimated required memory for 23409 words and 500 dimensions: 105340500 bytes\n",
      "2018-07-18 15:43:53,937 : INFO : resetting layer weights\n",
      "2018-07-18 15:43:54,264 : INFO : training model with 3 workers on 23409 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=5 window=15\n",
      "2018-07-18 15:43:54,637 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-18 15:43:54,641 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-18 15:43:54,646 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-18 15:43:54,647 : INFO : EPOCH - 1 : training on 206936 raw words (171163 effective words) took 0.4s, 451544 effective words/s\n",
      "2018-07-18 15:43:54,971 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-18 15:43:54,975 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-18 15:43:54,976 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-18 15:43:54,977 : INFO : EPOCH - 2 : training on 206936 raw words (171318 effective words) took 0.3s, 528277 effective words/s\n",
      "2018-07-18 15:43:55,305 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-18 15:43:55,312 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-18 15:43:55,317 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-18 15:43:55,318 : INFO : EPOCH - 3 : training on 206936 raw words (170926 effective words) took 0.3s, 508320 effective words/s\n",
      "2018-07-18 15:43:55,650 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-18 15:43:55,661 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-18 15:43:55,669 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-18 15:43:55,670 : INFO : EPOCH - 4 : training on 206936 raw words (171031 effective words) took 0.3s, 490230 effective words/s\n",
      "2018-07-18 15:43:55,996 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-18 15:43:56,001 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-18 15:43:56,009 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-18 15:43:56,010 : INFO : EPOCH - 5 : training on 206936 raw words (170983 effective words) took 0.3s, 506229 effective words/s\n",
      "2018-07-18 15:43:56,011 : INFO : training on a 1034680 raw words (855421 effective words) took 1.7s, 489963 effective words/s\n",
      "2018-07-18 15:43:56,021 : INFO : saving Word2Vec object under ./wiki.model, separately None\n",
      "2018-07-18 15:43:56,023 : INFO : storing np array 'vectors' to ./wiki.model.wv.vectors.npy\n",
      "2018-07-18 15:43:56,614 : INFO : not storing attribute vectors_norm\n",
      "2018-07-18 15:43:56,615 : INFO : storing np array 'syn1neg' to ./wiki.model.trainables.syn1neg.npy\n",
      "2018-07-18 15:43:56,824 : INFO : not storing attribute cum_table\n",
      "2018-07-18 15:43:56,872 : INFO : saved ./wiki.model\n"
     ]
    }
   ],
   "source": [
    "sentences = word2vec.Text8Corpus('quotes.txt')\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model = word2vec.Word2Vec(sentences, size=500, min_count=1, window=15)\n",
    "model.save(\"./wiki.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/eureka-engineering/pairs%E3%81%AE%E3%82%B3%E3%83%9F%E3%83%A5%E3%83%8B%E3%83%86%E3%82%A3%E3%82%92word2vec%E3%81%A8svm%E3%81%A7%E5%88%86%E9%A1%9E%E3%81%97%E3%81%A6%E3%81%BF%E3%81%9F-48f4099f0ffc\n",
    "def text_to_vec(words, model):\n",
    "    word_vecs = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_vecs.append(model[word])\n",
    "        except:\n",
    "            pass\n",
    "    if len(word_vecs) == 0:\n",
    "        return None\n",
    "    text_vec = numpy.zeros(word_vecs[0].shape, dtype = word_vecs[0].dtype)\n",
    "    for word_vec in word_vecs:\n",
    "        text_vec = text_vec + word_vec\n",
    "    return text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(vec):\n",
    "    return vec / numpy.linalg.norm(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/yuta0/opensuse/.anyenv/envs/pyenv/versions/miniconda3-4.3.30/envs/ML_practice/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "with open('quotes.txt', 'w') as f:\n",
    "    quotes = infos[1]\n",
    "    features = []\n",
    "    for quote in quotes:\n",
    "        quote_words = quote.rstrip().split(' ')\n",
    "        quote_name = ''.join(quote_words).replace(\"/\", \"\")[:10]\n",
    "        quote_vec = text_to_vec(quote_words, model)\n",
    "        quote_vec = normalize(quote_vec)\n",
    "        numpy.savetxt('./vec/' + quote_name, quote_vec)\n",
    "        features.append(quote_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = infos[0]\n",
    "# トレーニングデータ:テストデータ を 9:1 に分割\n",
    "data_train, data_test, label_train, label_test = train_test_split(features, labels, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82818043588444\n",
      "CPU times: user 922 ms, sys: 125 ms, total: 1.05 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# トレーニングデータから分類器を作成 (Linear SVM)\n",
    "estimator = LinearSVC(C=1.0)\n",
    "estimator.fit(data_train, label_train)\n",
    "# テストデータを分類器に入れる\n",
    "label_predict = estimator.predict(data_test)\n",
    "# Fscore\n",
    "print(f1_score(label_test, label_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
